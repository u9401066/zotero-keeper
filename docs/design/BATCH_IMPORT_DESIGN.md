# Batch Import Design Document

> **Version**: 1.2 Draft  
> **Date**: 2025-12-12  
> **Target Release**: v1.7.0  
> **Status**: Planning

---

## ğŸ¯ Design Principles (è¨­è¨ˆåŸå‰‡)

### 1. å­˜å°±å­˜æœ€å®Œæ•´çš„ï¼(Store Complete Metadata)

PubMed æä¾›è±å¯Œçš„ metadataï¼Œæˆ‘å€‘æ‡‰è©²**å…¨éƒ¨ä¿å­˜**åˆ° Zoteroï¼š

| âŒ ä»¥å‰ (v1.6.0) | âœ… ç¾åœ¨ (v1.7.0) |
|-----------------|-----------------|
| åªå­˜æ¨™é¡Œã€ä½œè€…ã€DOI | **å®Œæ•´æ‘˜è¦** (ä¸æˆªæ–·) |
| ç¼ºå°‘ MeSH è©å½™ | **Keywords + MeSH** â†’ tags |
| æ²’æœ‰æ©Ÿæ§‹è³‡è¨Š | **ä½œè€…æ©Ÿæ§‹** â†’ extra field |
| ç¼ºå°‘ PMC ID | **PMID + PMCID** å®Œæ•´ä¿å­˜ |

### 2. ç›´æ¥å–æœ€åŸå§‹è³‡æ–™ (Direct Source)

```
âŒ ä»¥å‰: pubmed-search.fetch_article_details() â†’ æˆªæ–·çš„æ‘˜è¦
âœ… ç¾åœ¨: NCBI E-utilities XML API â†’ å®Œæ•´åŸå§‹è³‡æ–™
```

### 3. MCP åˆ†å·¥æ˜ç¢º (Clear Responsibility)

```
pubmed-search-mcp: æœå°‹ã€å…¨æ–‡æª¢æŸ¥ã€å¼•ç”¨åˆ†æ
zotero-keeper:     æ‰¹æ¬¡åŒ¯å…¥ã€é‡è¤‡æª¢æ¸¬ã€PDF é™„åŠ 
```

---

## ğŸ¯ MCP Responsibility Split (é‡è¦!)

| Functionality | Responsible MCP | Tool | Notes |
|--------------|-----------------|------|-------|
| **Literature Search** | pubmed-search | `search_literature` | Keep as-is |
| **MeSH/Synonym Expansion** | pubmed-search | `generate_search_queries` | Keep as-is |
| **Fulltext Availability Check** | pubmed-search | `analyze_fulltext_access` | âš ï¸ DO NOT duplicate in keeper |
| **Fulltext URLs** | pubmed-search | `get_article_fulltext_links` | âš ï¸ DO NOT duplicate in keeper |
| **Citation Metrics** | pubmed-search | `get_citation_metrics` | Keep as-is |
| **Batch Import to Zotero** | zotero-keeper | `batch_import_from_pubmed` | NEW in v1.7.0 |
| **RIS Import** | zotero-keeper | `import_ris_to_zotero` | NEW in v1.7.0 |
| **Download & Attach PDFs** | zotero-keeper | `attach_pmc_pdfs` | NEW in v1.7.0 |
| **Duplicate Detection** | zotero-keeper | `check_duplicate`, `smart_add_reference` | Already exists |
| **Collection Management** | zotero-keeper | `create_collection`, `list_collections` | NEW/Existing |

**Principle: pubmed-search handles retrieval, zotero-keeper handles storage**

---

## ğŸ“‹ Executive Summary

### Problem Statement | å•é¡Œé™³è¿°

Current zotero-keeper v1.6.0 has three key limitations when importing literature from PubMed:

| Issue | Current Behavior | Impact |
|-------|------------------|--------|
| **No batch import** | `smart_add_reference` processes one article at a time | 50 articles = 50 API calls, slow and inefficient |
| **Two MCPs not unified** | Agent calls `pubmed-search` directly, bypassing keeper | Lost opportunity for duplicate filtering |
| **RIS export disconnected** | `prepare_export` creates file but doesn't auto-import | Manual workflow interruption |

### Proposed Solution | è§£æ±ºæ–¹æ¡ˆ

Implement **two complementary tools**:
1. **`batch_import_from_pubmed`** (Primary) - Direct batch import via metadata
2. **`import_ris_to_zotero`** (Backup) - Import via RIS format

---

## ğŸ—ï¸ Architecture Overview

### Current Flow (v1.6.0)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  pubmed-search  â”‚     â”‚  zotero-keeper  â”‚     â”‚     Zotero      â”‚
â”‚      MCP        â”‚     â”‚      MCP        â”‚     â”‚    Desktop      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
    search_literature â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                       â”‚
         â”‚                       â”‚                       â”‚
    prepare_export â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ (disconnected)       â”‚
         â”‚                       â”‚                       â”‚
         â”‚              smart_add_reference â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
         â”‚              smart_add_reference â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
         â”‚              smart_add_reference â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
         â”‚                  (N times)                    â”‚
```

### Proposed Flow (v1.7.0)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  pubmed-search  â”‚     â”‚  zotero-keeper  â”‚     â”‚     Zotero      â”‚
â”‚      MCP        â”‚     â”‚      MCP        â”‚     â”‚    Desktop      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚â—€â”€â”€ fetch_details â”€â”€â”€â”€â”‚                       â”‚
         â”‚    (internal call)    â”‚                       â”‚
         â”‚                       â”‚                       â”‚
         â”‚              batch_import_from_pubmed â”€â”€â”€â”€â”€â”€â–¶â”‚
         â”‚                  (single batch call)          â”‚
         â”‚                       â”‚                       â”‚
         â”‚                       â”‚â—€â”€â”€â”€ result â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
         â”‚                       â”‚                       â”‚
         â”‚              Return: {added: 45,              â”‚
         â”‚                       skipped: 3,             â”‚
         â”‚                       failed: 2}              â”‚
```

---

## ğŸ”§ Tool Specifications

### Tool A: `batch_import_from_pubmed` (Primary)

#### Signature
```python
@mcp.tool()
async def batch_import_from_pubmed(
    pmids: str,
    tags: list[str] | None = None,
    skip_duplicates: bool = True,
    batch_size: int = 10,
    collection_key: str | None = None
) -> BatchImportResult
```

#### Parameters

| Parameter | Type | Required | Default | Description |
|-----------|------|----------|---------|-------------|
| `pmids` | `str` | Yes | - | Comma-separated PMIDs (e.g., "12345,67890") or "last" for last search results |
| `tags` | `list[str]` | No | `None` | Tags to apply to all imported articles |
| `skip_exact_duplicates` | `bool` | No | `True` | Skip if exact DOI+PMID match found |
| `warn_on_similar` | `bool` | No | `True` | Add with warning if DOI matches but title differs |
| `similarity_threshold` | `float` | No | `0.85` | Title similarity threshold for duplicate detection (0-1) |
| `collection_key` | `str` | No | `None` | Zotero collection key to add items to directly |

#### Return Value
```python
class BatchImportResult(TypedDict):
    success: bool
    total: int
    added: int
    skipped: int              # Exact duplicates skipped
    warnings: int             # Added but with warnings (e.g., possible duplicate)
    failed: int
    added_items: list[dict]        # [{pmid, title, key}, ...]
    warning_items: list[dict]      # [{pmid, title, key, warning}, ...]  # NEW
    skipped_items: list[dict]      # [{pmid, title, reason}, ...]
    failed_items: list[dict]       # [{pmid, title, error}, ...]
    collection_key: str | None     # Collection items were added to  # NEW
    elapsed_time: float            # seconds
```

#### Algorithm
```
1. Parse PMIDs (comma-separated string â†’ list)

2. Fetch COMPLETE article metadata from PubMed E-utilities
   - Call NCBI efetch.fcgi with rettype=xml
   - Parse XML to extract ALL fields:
     âœ“ Title, Authors (with affiliations)
     âœ“ Abstract (FULL, not truncated!)
     âœ“ Journal, Volume, Issue, Pages
     âœ“ DOI, PMID, PMCID
     âœ“ Keywords (author-provided)
     âœ“ MeSH Terms (controlled vocabulary)
     âœ“ Publication Type
     âœ“ Language, Date

3. Pre-check duplicates (batch)
   - Query Zotero for existing DOIs and PMIDs
   - Build skip list

4. Map to Zotero schema (COMPLETE)
   - Apply pubmed_to_zotero_item() mapping
   - Include all metadata in appropriate fields
   - Keywords + MeSH â†’ tags
   - PMID/PMCID/Affiliations â†’ extra field

5. Import non-duplicates
   - For each article not in skip list:
     - Call Connector API saveItems
     - Apply user-provided tags

6. Return summary with full statistics
```

#### Example Usage
```
User: "Import all 30 anesthesia AI papers to Zotero with tag 'AI-Review'"

Agent:
batch_import_from_pubmed(
    pmids="38353755,37864754,38215710,...", 
    tags=["Anesthesia-AI", "AI-Review"]
)

Result:
{
    "success": true,
    "total": 30,
    "added": 27,
    "skipped": 2,
    "failed": 1,
    "added_items": [...],
    "skipped_items": [
        {"pmid": "38353755", "title": "...", "reason": "duplicate (DOI match)"}
    ],
    "failed_items": [
        {"pmid": "99999999", "title": "Unknown", "error": "PMID not found"}
    ],
    "elapsed_time": 12.5
}
```

---

### Tool B: `import_ris_to_zotero` (Backup)

#### Signature
```python
@mcp.tool()
async def import_ris_to_zotero(
    ris_content: str,
    tags: list[str] | None = None,
    skip_duplicates: bool = True
) -> RisImportResult
```

#### Parameters

| Parameter | Type | Required | Default | Description |
|-----------|------|----------|---------|-------------|
| `ris_content` | `str` | Yes | - | RIS format text content |
| `tags` | `list[str]` | No | `None` | Tags to apply to imported items |
| `skip_duplicates` | `bool` | No | `True` | Check duplicates before import |

#### Return Value
```python
class RisImportResult(TypedDict):
    success: bool
    total: int
    added: int
    skipped: int
    failed: int
    message: str
```

#### Algorithm
```
1. Parse RIS content
   - Extract individual records (separated by "ER  -")
   - Parse fields: TY, TI, AU, JO, PY, DO, AN (PMID), AB
2. Convert to Zotero format
   - Map RIS fields to Zotero item schema
3. Check duplicates (if enabled)
   - By DOI, PMID, or fuzzy title match
4. Import via Connector API
   - POST /connector/saveItems
5. Return summary
```

#### Example Usage
```
User: "Import this RIS file to Zotero"

Agent:
import_ris_to_zotero(
    ris_content="TY  - JOUR\nTI  - ...\nER  -\n...",
    tags=["Imported"]
)
```

---

## ğŸ”— Metadata Source: Direct NCBI E-utilities (å®Œæ•´è³‡æ–™!)

### Why Direct NCBI API? (Not via pubmed-search-mcp)

| Approach | Pros | Cons | Decision |
|----------|------|------|----------|
| **pubmed-search's fetch_article_details** | Simple, already exists | âŒ Returns truncated abstract, missing fields | âŒ Not used |
| **Direct NCBI E-utilities XML** | âœ… Complete metadata, all fields | Need to parse XML | âœ… **Use this** |

### NCBI E-utilities API Details

```
Endpoint: https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi
Parameters:
  - db=pubmed
  - id={comma-separated PMIDs}
  - rettype=xml
  - retmode=text
```

### Implementation: `pubmed_client.py`

```python
import httpx
import xml.etree.ElementTree as ET
from dataclasses import dataclass

@dataclass
class PubMedArticle:
    """Complete PubMed article metadata"""
    pmid: str
    title: str
    abstract: str  # FULL abstract!
    authors: list[dict]  # [{firstName, lastName, affiliation}]
    journal: str
    date: str
    volume: str | None
    issue: str | None
    pages: str | None
    doi: str | None
    pmc_id: str | None
    issn: str | None
    language: str
    keywords: list[str]
    mesh_terms: list[str]
    pub_types: list[str]
    affiliations: list[str]


class PubMedClient:
    """Direct NCBI E-utilities client for complete metadata"""
    
    BASE_URL = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils"
    
    async def fetch_articles(self, pmids: list[str]) -> list[PubMedArticle]:
        """Fetch complete metadata for multiple PMIDs"""
        
        url = f"{self.BASE_URL}/efetch.fcgi"
        params = {
            "db": "pubmed",
            "id": ",".join(pmids),
            "rettype": "xml",
            "retmode": "text"
        }
        
        async with httpx.AsyncClient() as client:
            response = await client.get(url, params=params, timeout=30.0)
            response.raise_for_status()
        
        return self._parse_pubmed_xml(response.text)
    
    def _parse_pubmed_xml(self, xml_text: str) -> list[PubMedArticle]:
        """Parse PubMed XML to extract complete metadata"""
        
        root = ET.fromstring(xml_text)
        articles = []
        
        for article_elem in root.findall(".//PubmedArticle"):
            articles.append(self._parse_article(article_elem))
        
        return articles
    
    def _parse_article(self, elem) -> PubMedArticle:
        """Parse single article element"""
        
        # PMID
        pmid = elem.findtext(".//PMID", "")
        
        # Title
        title = elem.findtext(".//ArticleTitle", "")
        
        # Abstract (FULL!)
        abstract_parts = elem.findall(".//Abstract/AbstractText")
        if abstract_parts:
            abstract = " ".join(
                (part.get("Label", "") + ": " if part.get("Label") else "") + 
                (part.text or "")
                for part in abstract_parts
            )
        else:
            abstract = ""
        
        # Authors with affiliations
        authors = []
        for author_elem in elem.findall(".//Author"):
            author = {
                "lastName": author_elem.findtext("LastName", ""),
                "firstName": author_elem.findtext("ForeName", ""),
                "affiliation": author_elem.findtext(".//Affiliation", "")
            }
            if author["lastName"]:  # Skip empty authors
                authors.append(author)
        
        # Journal info
        journal = elem.findtext(".//Journal/Title", "")
        volume = elem.findtext(".//Volume")
        issue = elem.findtext(".//Issue")
        pages = elem.findtext(".//MedlinePgn")
        issn = elem.findtext(".//ISSN")
        
        # Date (prefer ArticleDate, fallback to PubDate)
        article_date = elem.find(".//ArticleDate")
        pub_date = elem.find(".//PubDate")
        if article_date is not None:
            year = article_date.findtext("Year", "")
            month = article_date.findtext("Month", "")
            day = article_date.findtext("Day", "")
            date = f"{year}-{month.zfill(2)}-{day.zfill(2)}" if month and day else year
        elif pub_date is not None:
            date = pub_date.findtext("Year", "")
        else:
            date = ""
        
        # DOI
        doi = None
        for eloc in elem.findall(".//ELocationID"):
            if eloc.get("EIdType") == "doi":
                doi = eloc.text
                break
        
        # PMC ID
        pmc_id = None
        for article_id in elem.findall(".//ArticleId"):
            if article_id.get("IdType") == "pmc":
                pmc_id = article_id.text
                break
        
        # Language
        language = elem.findtext(".//Language", "eng")
        
        # Keywords
        keywords = [kw.text for kw in elem.findall(".//Keyword") if kw.text]
        
        # MeSH terms
        mesh_terms = [
            mesh.findtext("DescriptorName", "")
            for mesh in elem.findall(".//MeshHeading")
        ]
        mesh_terms = [m for m in mesh_terms if m]
        
        # Publication types
        pub_types = [pt.text for pt in elem.findall(".//PublicationType") if pt.text]
        
        # Unique affiliations
        affiliations = list(set(a["affiliation"] for a in authors if a["affiliation"]))
        
        return PubMedArticle(
            pmid=pmid,
            title=title,
            abstract=abstract,
            authors=authors,
            journal=journal,
            date=date,
            volume=volume,
            issue=issue,
            pages=pages,
            doi=doi,
            pmc_id=pmc_id,
            issn=issn,
            language=language,
            keywords=keywords,
            mesh_terms=mesh_terms,
            pub_types=pub_types,
            affiliations=affiliations
        )
```

---

## ğŸ“Š Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        batch_import_from_pubmed                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                           â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 1. Parse PMIDs   â”‚         â”‚ 2. Fetch Metadataâ”‚
        â”‚    (internal)    â”‚         â”‚    from PubMed   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚                            â”‚
                 â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚         â–¼
                 â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  â”‚ NCBI E-utilities â”‚
                 â”‚  â”‚ efetch.fcgi      â”‚
                 â”‚  â”‚ (XML format)     â”‚
                 â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚           â”‚
                 â–¼           â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 3. Parse COMPLETE Metadata   â”‚
        â”‚    - Title, Authors          â”‚
        â”‚    - Abstract (FULL!)        â”‚
        â”‚    - Keywords, MeSH          â”‚
        â”‚    - Affiliations            â”‚
        â”‚    - References              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â–¼                         â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ 4. Duplicate    â”‚       â”‚ 5. Map to       â”‚
   â”‚    Check        â”‚       â”‚    Zotero Schemaâ”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                         â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ 6. Batch Import      â”‚
              â”‚    Connector API     â”‚
              â”‚    /saveItems        â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ 7. Return Summary    â”‚
              â”‚    BatchImportResult â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Complete Metadata Mapping (å­˜å°±å­˜æœ€å®Œæ•´çš„!)

### PubMed E-utilities XML â†’ Zotero Schema

| PubMed XML Path | Zotero Field | Example | Priority |
|-----------------|--------------|---------|----------|
| `PMID` | `extra` (PMID: xxx) | 38353755 | â­ P0 |
| `ArticleTitle` | `title` | Artificial Intelligence in... | â­ P0 |
| `Abstract/AbstractText` | `abstractNote` | **å®Œæ•´æ‘˜è¦** (ä¸æˆªæ–·!) | â­ P0 |
| `Author/LastName` + `ForeName` | `creators[]` | Bellini Valentina | â­ P0 |
| `Journal/Title` | `publicationTitle` | Journal of medical systems | â­ P0 |
| `PubDate/Year` | `date` | 2024 | â­ P0 |
| `ELocationID[@EIdType="doi"]` | `DOI` | 10.1007/s10916-024-02038-2 | â­ P0 |
| `ArticleId[@IdType="pmc"]` | `extra` (PMCID: xxx) | PMC10867065 | â­ P0 |
| `Volume` | `volume` | 48 | P1 |
| `Issue` | `issue` | 1 | P1 |
| `MedlinePgn` / `StartPage` | `pages` | 19 | P1 |
| `ISSN` | `ISSN` | 1573-689X | P1 |
| `AffiliationInfo/Affiliation` | `extra` (å¤šè¡Œ) | University of Parma... | P1 |
| `KeywordList/Keyword` | `tags[]` | ["AI", "Machine learning"...] | P1 |
| `MeshHeading/DescriptorName` | `tags[]` (prefix: MeSH:) | ["MeSH: Operating Rooms"...] | P2 |
| `PublicationType` | `extra` | Systematic Review | P2 |
| `Language` | `language` | eng | P2 |
| `ArticleDate` | `date` (precise) | 2024-02-14 | P2 |
| `CoiStatement` | `extra` | Conflict of interest... | P3 |
| `ReferenceList` | (future: linked items) | - | P3 |

### Zotero Item Schema (Complete)

```python
def pubmed_to_zotero_item(pubmed_data: dict) -> dict:
    """Convert PubMed metadata to Zotero journalArticle schema"""
    
    return {
        "itemType": "journalArticle",
        
        # === P0: Core Fields (å¿…å¡«) ===
        "title": pubmed_data["title"],
        "creators": [
            {
                "creatorType": "author",
                "firstName": author["forename"],
                "lastName": author["lastname"]
            }
            for author in pubmed_data["authors"]
        ],
        "abstractNote": pubmed_data["abstract"],  # å®Œæ•´æ‘˜è¦!
        "publicationTitle": pubmed_data["journal"],
        "date": pubmed_data["date"],  # YYYY-MM-DD or YYYY
        "DOI": pubmed_data.get("doi"),
        
        # === P1: Publication Details ===
        "volume": pubmed_data.get("volume"),
        "issue": pubmed_data.get("issue"),
        "pages": pubmed_data.get("pages"),
        "ISSN": pubmed_data.get("issn"),
        "language": pubmed_data.get("language", "eng"),
        
        # === P1: Identifiers & URLs ===
        "url": f"https://pubmed.ncbi.nlm.nih.gov/{pubmed_data['pmid']}/",
        
        # === P1-P2: Tags (Keywords + MeSH) ===
        "tags": [
            # User keywords
            *[{"tag": kw} for kw in pubmed_data.get("keywords", [])],
            # MeSH terms with prefix
            *[{"tag": f"MeSH: {mesh}"} for mesh in pubmed_data.get("mesh_terms", [])]
        ],
        
        # === P2: Extra Field (structured) ===
        "extra": _build_extra_field(pubmed_data),
        
        # === Attachments (handled separately) ===
        # PDF attachment added via attach_pmc_pdfs tool
    }


def _build_extra_field(pubmed_data: dict) -> str:
    """Build structured Extra field for additional metadata"""
    
    lines = []
    
    # Identifiers
    lines.append(f"PMID: {pubmed_data['pmid']}")
    if pubmed_data.get("pmc_id"):
        lines.append(f"PMCID: {pubmed_data['pmc_id']}")
    
    # Publication type
    if pubmed_data.get("pub_types"):
        lines.append(f"Publication Type: {', '.join(pubmed_data['pub_types'])}")
    
    # Affiliations (first 3, truncate if too long)
    if pubmed_data.get("affiliations"):
        lines.append("Affiliations:")
        for i, aff in enumerate(pubmed_data["affiliations"][:3]):
            lines.append(f"  {i+1}. {aff[:200]}")  # Truncate long affiliations
    
    # Grant info (if available)
    if pubmed_data.get("grants"):
        lines.append(f"Grants: {', '.join(pubmed_data['grants'][:3])}")
    
    return "\n".join(lines)
```

### Example: Complete Zotero Item

```json
{
    "itemType": "journalArticle",
    "title": "Artificial Intelligence in Operating Room Management",
    "creators": [
        {"creatorType": "author", "firstName": "Valentina", "lastName": "Bellini"},
        {"creatorType": "author", "firstName": "Michele", "lastName": "Russo"},
        {"creatorType": "author", "firstName": "Tania", "lastName": "Domenichetti"},
        {"creatorType": "author", "firstName": "Matteo", "lastName": "Panizzi"},
        {"creatorType": "author", "firstName": "Simone", "lastName": "Allai"},
        {"creatorType": "author", "firstName": "Elena Giovanna", "lastName": "Bignami"}
    ],
    "abstractNote": "This systematic review examines the recent use of artificial intelligence, particularly machine learning, in the management of operating rooms. A total of 22 selected studies from February 2019 to September 2023 are analyzed. The review emphasizes the significant impact of AI on predicting surgical case durations, optimizing post-anesthesia care unit resource allocation, and detecting surgical case cancellations. Machine learning algorithms such as XGBoost, random forest, and neural networks have demonstrated their effectiveness in improving prediction accuracy and resource utilization. However, challenges such as data access and privacy concerns are acknowledged. The review highlights the evolving nature of artificial intelligence in perioperative medicine research and the need for continued innovation to harness artificial intelligence's transformative potential for healthcare administrators, practitioners, and patients. Ultimately, artificial intelligence integration in operative room management promises to enhance healthcare efficiency and patient outcomes.",
    "publicationTitle": "Journal of medical systems",
    "date": "2024-02-14",
    "DOI": "10.1007/s10916-024-02038-2",
    "volume": "48",
    "issue": "1",
    "pages": "19",
    "ISSN": "1573-689X",
    "language": "eng",
    "url": "https://pubmed.ncbi.nlm.nih.gov/38353755/",
    "tags": [
        {"tag": "Artificial intelligence"},
        {"tag": "Machine learning"},
        {"tag": "Management"},
        {"tag": "Operating room"},
        {"tag": "Perioperative"},
        {"tag": "MeSH: Operating Rooms"},
        {"tag": "MeSH: Machine Learning"},
        {"tag": "MeSH: Efficiency, Organizational"}
    ],
    "extra": "PMID: 38353755\nPMCID: PMC10867065\nPublication Type: Journal Article, Systematic Review\nAffiliations:\n  1. Anesthesiology, Intensive Care and Pain Medicine Division, Department of Medicine and Surgery, University of Parma, Parma, 43126, Italy."
}
```

---

## ğŸ§ª Test Cases

### Unit Tests

| Test Case | Input | Expected Output |
|-----------|-------|-----------------|
| Single PMID | `pmids="38353755"` | 1 article imported |
| Multiple PMIDs | `pmids="38353755,37864754"` | 2 articles imported |
| Invalid PMID | `pmids="99999999"` | failed=1, error message |
| Duplicate check | Import same PMID twice | Second import: skipped=1 |
| With tags | `tags=["AI", "2024"]` | Articles have tags |
| Empty input | `pmids=""` | Error: no PMIDs provided |
| Malformed input | `pmids="abc,def"` | Error: invalid PMID format |

### Integration Tests

| Test Case | Description |
|-----------|-------------|
| Full workflow | Search â†’ Import â†’ Verify in Zotero |
| Large batch | Import 50 articles at once |
| Network failure | Handle PubMed API timeout |
| Zotero offline | Handle Zotero not running |

---

## ğŸ“ File Structure Changes

```
mcp-server/src/zotero_mcp/
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ mcp/
â”‚   â”‚   â”œâ”€â”€ tools.py              # Existing read tools
â”‚   â”‚   â”œâ”€â”€ write_tools.py        # Existing write tools
â”‚   â”‚   â”œâ”€â”€ smart_tools.py        # Existing smart tools
â”‚   â”‚   â”œâ”€â”€ search_tools.py       # Existing integrated search
â”‚   â”‚   â””â”€â”€ batch_tools.py        # NEW: batch import tools â­
â”‚   â”‚                              #   - batch_import_from_pubmed
â”‚   â”‚                              #   - import_ris_to_zotero
â”‚   â”‚                              #   - attach_pmc_pdfs
â”‚   â”‚
â”‚   â”œâ”€â”€ pubmed/                    # NEW: PubMed integration â­
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ pubmed_client.py      # NCBI E-utilities XML API client
â”‚   â”‚   â”œâ”€â”€ xml_parser.py         # PubMed XML â†’ PubMedArticle
â”‚   â”‚   â””â”€â”€ zotero_mapper.py      # PubMedArticle â†’ Zotero schema
â”‚   â”‚
â”‚   â””â”€â”€ zotero_client/
â”‚       â””â”€â”€ client.py             # Add batch operations
â”‚
â”œâ”€â”€ domain/
â”‚   â””â”€â”€ entities/
â”‚       â”œâ”€â”€ pubmed_article.py     # NEW: Complete PubMed metadata â­
â”‚       â””â”€â”€ batch_result.py       # NEW: BatchImportResult â­
â”‚
â””â”€â”€ application/
    â””â”€â”€ use_cases/
        â””â”€â”€ batch_import.py       # NEW: BatchImportUseCase â­
```

### New Dependencies

```toml
# pyproject.toml additions
dependencies = [
    # ... existing ...
    "defusedxml>=0.7.1",  # Safe XML parsing (security)
]
```

---

## ğŸš€ Implementation Plan

### Phase 1: Core Infrastructure (Day 1)
- [ ] Create `pubmed_client.py` with NCBI E-utilities integration
- [ ] Create `batch_result.py` domain entity
- [ ] Add batch duplicate checking to `zotero_client.py`

### Phase 2: Primary Tool (Day 2)
- [ ] Implement `batch_import_from_pubmed` in `batch_tools.py`
- [ ] Unit tests for batch import
- [ ] Integration test with real Zotero

### Phase 3: Backup Tool (Day 3)
- [ ] Implement RIS parser
- [ ] Implement `import_ris_to_zotero`
- [ ] Unit tests for RIS import

### Phase 4: Documentation & Release (Day 4)
- [ ] Update README with new tools
- [ ] Update CHANGELOG
- [ ] Tag v1.7.0 release

---

## ğŸ”’ Security Considerations

| Concern | Mitigation |
|---------|------------|
| NCBI API rate limiting | Implement exponential backoff, respect 3 req/sec |
| Large batch size | Limit to 100 PMIDs per call |
| Malicious RIS content | Sanitize input, validate format |
| Network timeouts | Set reasonable timeouts (30s), retry logic |

---

## ğŸ“ˆ Success Metrics

| Metric | Target |
|--------|--------|
| Batch import speed | 50 articles in < 30 seconds |
| Success rate | > 95% for valid PMIDs |
| Duplicate detection accuracy | > 99% |
| User workflow reduction | 50 calls â†’ 1 call |

---

## âœ… Design Decisions (Confirmed 2025-12-12)

| Question | Decision | Rationale |
|----------|----------|----------|
| **Collection support** | âœ… Add `collection_key` parameter | Allow direct organization during import |
| **Progress reporting** | âœ… Wait for completion, return summary | Keep implementation simple, avoid complexity |
| **Conflict resolution** | âœ… Add with warning flag | Don't lose data, let user decide later |

### Decision Details

#### 1. Collection Support
```python
batch_import_from_pubmed(
    pmids="...",
    collection_key="EXSL84KZ"  # Optional: add to specific collection
)
```
- If `collection_key` provided â†’ add items to that collection after import
- If not provided â†’ add to "My Library" (default behavior)
- Implementation: Use Zotero Local API to add item to collection after creation

#### 2. Progress Reporting
```python
# Return complete summary at end
return {
    "success": True,
    "total": 50,
    "added": 47,
    "skipped": 2,
    "failed": 1,
    "warnings": 3,  # NEW: count of warning items
    "elapsed_time": 15.2
}
```
- Simple synchronous operation
- No intermediate progress updates
- Suitable for batches up to ~100 items

#### 3. Conflict Resolution
```python
# When DOI exists but title differs significantly
{
    "pmid": "12345678",
    "title": "New Title Here",
    "action": "added_with_warning",
    "warning": "DOI match found but title differs (similarity: 65%)",
    "existing_key": "ABC12345"  # Reference to existing item
}
```
- Add the item anyway (don't lose data)
- Flag with warning in result
- Include reference to potentially duplicate item
- User can manually review and merge later

---

## ğŸ†• Advanced Design: Agent Collaboration (v1.7.0)

### Collection Workflow: No Collection? Ask User!

When user wants to import but no collection exists, the MCP should guide the agent to ask:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User: "Import anesthesia AI papers to Zotero"                  â”‚
â”‚                                                                 â”‚
â”‚  Agent checks: list_collections() â†’ []  (empty)                 â”‚
â”‚                                                                 â”‚
â”‚  MCP returns:                                                   â”‚
â”‚  {                                                              â”‚
â”‚    "status": "no_collection",                                   â”‚
â”‚    "prompt_user": true,                                         â”‚
â”‚    "message": "No collections found. Would you like to:",       â”‚
â”‚    "options": [                                                 â”‚
â”‚      "1. Create a new collection (name suggestion: 'éº»é†‰AI')",  â”‚
â”‚      "2. Import to My Library (organize later)",                â”‚
â”‚      "3. Let me suggest a collection name based on search"      â”‚
â”‚    ]                                                            â”‚
â”‚  }                                                              â”‚
â”‚                                                                 â”‚
â”‚  Agent asks user which option they prefer                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### New Tool: `suggest_collection_name`
```python
@mcp.tool()
async def suggest_collection_name(
    pmids: str | None = None,
    search_query: str | None = None
) -> dict:
    """
    Suggest a collection name based on article topics.
    
    Returns:
    {
        "suggestions": [
            "Anesthesia-AI (2024-2025)",
            "Machine Learning in Anesthesiology",
            "AI Clinical Applications"
        ],
        "common_keywords": ["artificial intelligence", "anesthesia", "machine learning"],
        "date_range": "2024-2025"
    }
    """
```

#### New Tool: `create_collection` (if Zotero API supports)
```python
@mcp.tool()
async def create_collection(
    name: str,
    parent_key: str | None = None
) -> dict:
    """
    Create a new Zotero collection.
    
    Note: Requires Zotero Connector API or manual creation.
    Returns instructions if API not available.
    """
```

---

### Conflict Resolution: Return JSON for Agent Discussion

When conflicts are found, return structured data for agent to discuss with user:

```python
class BatchImportResult(TypedDict):
    # ... existing fields ...
    
    # NEW: Structured conflict data for agent
    conflicts: list[ConflictItem]
    conflict_summary: str  # Human-readable summary for agent to relay

class ConflictItem(TypedDict):
    pmid: str
    new_title: str
    new_doi: str | None
    existing_item: dict  # {key, title, doi, date}
    similarity_score: float
    conflict_type: str  # "doi_match_title_differs", "title_similar_no_doi", etc.
    suggested_action: str  # "merge", "keep_both", "skip"
```

#### Example Response with Conflicts
```json
{
    "success": true,
    "total": 30,
    "added": 25,
    "skipped": 2,
    "warnings": 3,
    "conflicts": [
        {
            "pmid": "38353755",
            "new_title": "AI in Operating Room Management (Updated)",
            "new_doi": "10.1007/s10916-024-02038-2",
            "existing_item": {
                "key": "BIZDPR9V",
                "title": "Artificial Intelligence in Operating Room Management",
                "doi": "10.1007/s10916-024-02038-2",
                "date": "2024"
            },
            "similarity_score": 0.78,
            "conflict_type": "doi_match_title_differs",
            "suggested_action": "skip"
        }
    ],
    "conflict_summary": "Found 3 potential conflicts:\n- 2 articles have matching DOI but different titles\n- 1 article has similar title (78% match)\n\nWould you like to review these individually?"
}
```

Agent can then ask user:
> "I found 3 potential conflicts. For example, PMID 38353755 has the same DOI as an existing article but the title is slightly different. Would you like to: (1) Skip these, (2) Add anyway, (3) Review each one?"

---

### Fulltext/Abstract Check: Use pubmed-search-mcp (Already Exists!)

**pubmed-search-mcp already provides:**
- `analyze_fulltext_access(pmids)` - Check PMC availability for multiple articles
- `get_article_fulltext_links(pmid)` - Get fulltext URLs for single article

#### Example Response from pubmed-search
```json
{
  "summary": {
    "total": 30,
    "open_access": 12,
    "subscription": 15,
    "abstract_only": 3,
    "pmc_available": [
      {"pmid": "38353755", "pmc_pdf_url": "https://..."}
    ],
    "pmc_percentage": 40.0
  }
}
```

#### zotero-keeper Collaboration: Download & Attach PDFs

**NEW Tool in zotero-keeper: `attach_pmc_pdfs`**
```python
@mcp.tool()
async def attach_pmc_pdfs(
    pmids: str,
    item_keys: str | None = None  # Optional: map PMIDs to Zotero item keys
) -> dict:
    """
    Download PMC PDFs and attach to Zotero items.
    
    Workflow:
    1. Call pubmed-search's get_article_fulltext_links for each PMID
    2. Download PDFs from PMC
    3. Attach to corresponding Zotero items
    
    Returns:
    {
        "total": 12,
        "attached": 10,
        "failed": 2,
        "failed_items": [{"pmid": "...", "error": "..."}]
    }
    """
```

#### Workflow Integration
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  After batch_import_from_pubmed:                                â”‚
â”‚                                                                 â”‚
â”‚  Agent: "Import complete! 30 articles added."                   â”‚
â”‚                                                                 â”‚
â”‚  [pubmed] analyze_fulltext_access(pmids)                        â”‚
â”‚  â†’ "12 articles have free PMC fulltext (40%)"                   â”‚
â”‚                                                                 â”‚
â”‚  Agent: "12 of your imported articles have free PDFs.           â”‚
â”‚          Would you like me to download and attach them?"        â”‚
â”‚                                                                 â”‚
â”‚  User: "Yes"                                                    â”‚
â”‚                                                                 â”‚
â”‚  [keeper] attach_pmc_pdfs(pmids="38353755,37864754,...")        â”‚
â”‚  â†’ Downloads and attaches PDFs to Zotero items                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Responsibility Split

| Task | MCP | Tool |
|------|-----|------|
| Check fulltext availability | pubmed-search | `analyze_fulltext_access` |
| Get fulltext URLs | pubmed-search | `get_article_fulltext_links` |
| Download & attach PDFs | zotero-keeper | `attach_pmc_pdfs` (NEW) |

---

## ğŸ”— MCP Integration Strategy

### Problem: How to unify pubmed-search + zotero-keeper?

Three approaches, from least to most invasive:

### Approach 1: System Prompt Instructions (Recommended) âœ…

Add instructions to `.vscode/mcp.json` or agent system prompt:

```json
{
  "servers": {
    "zotero-keeper": {
      "type": "stdio",
      "command": "...",
      "instructions": "When user asks to search PubMed for literature to add to Zotero, prefer using zotero-keeper's integrated tools (search_and_import, batch_import_from_pubmed) over direct pubmed-search calls. This ensures duplicate checking and proper organization."
    }
  }
}
```

**Pros**: No code changes, flexible  
**Cons**: Agent may not always follow

### Approach 2: Tool Shadowing / Wrapping

zotero-keeper provides wrapper tools that internally call pubmed-search:

```python
# In zotero-keeper
@mcp.tool()
async def search_pubmed(
    query: str,
    limit: int = 20,
    min_year: int | None = None
) -> dict:
    """
    Search PubMed for articles (wrapper with Zotero integration).
    
    This is the PREFERRED way to search when working with Zotero.
    Automatically checks which articles you already own.
    
    For raw PubMed search without Zotero integration, 
    use pubmed-search MCP directly.
    """
    # 1. Call pubmed-search's search_literature
    # 2. Check against Zotero library
    # 3. Return annotated results with "owned" flag
```

**Pros**: Seamless integration  
**Cons**: Tool name collision possible

### Approach 3: Resource-based Integration

Use MCP Resources to share state:

```python
# zotero-keeper exposes a resource
@mcp.resource("zotero://owned-pmids")
async def get_owned_pmids() -> str:
    """List of PMIDs already in Zotero library"""
    items = await zotero_client.search_items("")
    pmids = [item.get("pmid") for item in items if item.get("pmid")]
    return json.dumps(pmids)

# pubmed-search can read this resource to filter results
# (requires pubmed-search to support this)
```

**Pros**: Clean separation, shared state  
**Cons**: Requires both MCPs to coordinate

### Recommended Strategy: Hybrid

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RECOMMENDED APPROACH                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. System Prompt (immediate):                                  â”‚
â”‚     "For literature management, use zotero-keeper's             â”‚
â”‚      integrated tools instead of raw pubmed-search"             â”‚
â”‚                                                                 â”‚
â”‚  2. Tool Shadowing (v1.7.0):                                    â”‚
â”‚     zotero-keeper provides `search_pubmed_for_import`           â”‚
â”‚     that wraps pubmed-search with Zotero integration            â”‚
â”‚                                                                 â”‚
â”‚  3. Future (v2.0):                                              â”‚
â”‚     Consider merging into single MCP or using Resources         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Updated Tool List (v1.7.0)

### New Tools

| Tool | Purpose | Priority |
|------|---------|----------|
| `batch_import_from_pubmed` | Batch import PMIDs | P0 (Core) |
| `import_ris_to_zotero` | Import RIS format | P1 |
| `attach_pmc_pdfs` | Download & attach PMC PDFs | P2 |
| `suggest_collection_name` | AI-assisted naming | P2 |
| `create_collection` | Create new collection | P2 |
| `search_pubmed_for_import` | Integrated search wrapper | P1 |

### Delegated to pubmed-search-mcp (DO NOT DUPLICATE)

| Tool | Purpose | Notes |
|------|---------|-------|
| `analyze_fulltext_access` | Check PMC/OA status | Already exists in pubmed-search |
| `get_article_fulltext_links` | Get fulltext URLs | Already exists in pubmed-search |

### Modified Tools

| Tool | Change |
|------|--------|
| `smart_add_reference` | Add `collection_key` parameter |
| `list_collections` | Add `prompt_for_creation` hint in response |

---

## ğŸ”„ Updated Workflow (å®Œæ•´ Metadata ç‰ˆæœ¬)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Complete Literature Import Workflow (v1.7.0)                   â”‚
â”‚  ğŸ¯ è¨­è¨ˆåŸå‰‡: å­˜å°±å­˜æœ€å®Œæ•´çš„!                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User: "Find and import 2024-2025 anesthesia AI papers to Zotero"

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 1: Search via pubmed-search                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [pubmed] search_literature(                                     â”‚
â”‚     query="anesthesia artificial intelligence",                 â”‚
â”‚     min_year=2024, limit=50                                     â”‚
â”‚ )                                                               â”‚
â”‚ â†’ Returns PMIDs + basic info (titles, authors)                  â”‚
â”‚ â†’ "Found 50 articles matching your query"                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 2: Check Fulltext Availability                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [pubmed] analyze_fulltext_access(pmids="...")                   â”‚
â”‚ â†’ "25 have PMC fulltext (free PDF), 25 subscription only"       â”‚
â”‚ â†’ Agent asks: "Import all 50, or only those with free fulltext?"â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 3: Batch Import with COMPLETE Metadata                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [keeper] batch_import_from_pubmed(                              â”‚
â”‚     pmids="38353755,37864754,...",                              â”‚
â”‚     tags=["Anesthesia-AI"],                                     â”‚
â”‚     collection_key="EXSL84KZ"                                   â”‚
â”‚ )                                                               â”‚
â”‚                                                                 â”‚
â”‚ ğŸ”„ Internal Process:                                            â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ 1. NCBI E-utilities efetch.fcgi (XML format)                â”‚ â”‚
â”‚ â”‚    â†’ Fetch COMPLETE metadata for all PMIDs                  â”‚ â”‚
â”‚ â”‚                                                             â”‚ â”‚
â”‚ â”‚ 2. Parse XML to extract:                                    â”‚ â”‚
â”‚ â”‚    âœ“ Title, Authors (with affiliations!)                    â”‚ â”‚
â”‚ â”‚    âœ“ Abstract (FULL - not truncated!)                       â”‚ â”‚
â”‚ â”‚    âœ“ Journal, Volume, Issue, Pages                          â”‚ â”‚
â”‚ â”‚    âœ“ DOI, PMID, PMCID                                       â”‚ â”‚
â”‚ â”‚    âœ“ Keywords (author-provided)                             â”‚ â”‚
â”‚ â”‚    âœ“ MeSH Terms (controlled vocabulary)                     â”‚ â”‚
â”‚ â”‚    âœ“ Publication Type, Language                             â”‚ â”‚
â”‚ â”‚                                                             â”‚ â”‚
â”‚ â”‚ 3. Duplicate check against Zotero                           â”‚ â”‚
â”‚ â”‚    â†’ Match by DOI/PMID/Title                                â”‚ â”‚
â”‚ â”‚                                                             â”‚ â”‚
â”‚ â”‚ 4. Map to Zotero schema:                                    â”‚ â”‚
â”‚ â”‚    - title â†’ title                                          â”‚ â”‚
â”‚ â”‚    - authors â†’ creators[]                                   â”‚ â”‚
â”‚ â”‚    - abstract â†’ abstractNote (å®Œæ•´!)                        â”‚ â”‚
â”‚ â”‚    - keywords + MeSH â†’ tags[]                               â”‚ â”‚
â”‚ â”‚    - PMID/PMCID/affiliations â†’ extra                        â”‚ â”‚
â”‚ â”‚                                                             â”‚ â”‚
â”‚ â”‚ 5. Batch write to Zotero via Connector API                  â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚ â†’ Result: added=47, skipped=2 (duplicates), warnings=1          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 4: Download PDFs (Optional)                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Agent: "47 articles imported! 25 have free PMC fulltext.        â”‚
â”‚         Would you like me to download and attach the PDFs?"     â”‚
â”‚                                                                 â”‚
â”‚ User: "Yes, download them"                                      â”‚
â”‚                                                                 â”‚
â”‚ [keeper] attach_pmc_pdfs(pmids="38353755,37864754,...")         â”‚
â”‚ â†’ Downloads PDFs from PMC                                       â”‚
â”‚ â†’ Attaches to corresponding Zotero items                        â”‚
â”‚ â†’ Result: attached=23, failed=2 (PDF not available)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Final Result in Zotero:                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚ Collection: éº»é†‰AI (2024-2025)                                  â”‚
â”‚ â”œâ”€â”€ ğŸ“„ Artificial Intelligence in Operating Room Management     â”‚
â”‚ â”‚   â”œâ”€â”€ Authors: Bellini V, Russo M, Domenichetti T, et al.    â”‚
â”‚ â”‚   â”œâ”€â”€ Abstract: This systematic review examines... (å®Œæ•´!)   â”‚
â”‚ â”‚   â”œâ”€â”€ Tags: AI, Machine learning, MeSH: Operating Rooms...   â”‚
â”‚ â”‚   â”œâ”€â”€ PMID: 38353755 | PMCID: PMC10867065                    â”‚
â”‚ â”‚   â””â”€â”€ ğŸ“ PDF (attached from PMC)                              â”‚
â”‚ â”‚                                                               â”‚
â”‚ â”œâ”€â”€ ğŸ“„ Machine Learning for Anesthesia...                       â”‚
â”‚ â”‚   â””â”€â”€ ...                                                     â”‚
â”‚ â””â”€â”€ ... (47 total articles)                                     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Before vs After

| Aspect | v1.6.0 (Before) | v1.7.0 (After) |
|--------|-----------------|----------------|
| **Import Method** | One by one (N API calls) | Batch (1 call) |
| **Abstract** | Manual entry | âœ… FULL, automatic |
| **Keywords** | Manual | âœ… Author keywords + MeSH |
| **Affiliations** | None | âœ… In extra field |
| **PDF Attachment** | Manual | âœ… Automatic from PMC |
| **Duplicate Check** | Per-item | âœ… Batch |
| **Time for 50 articles** | ~10 minutes | ~30 seconds |

---

## ğŸ“ Appendix

### A. NCBI E-utilities Reference
- Base URL: `https://eutils.ncbi.nlm.nih.gov/entrez/eutils/`
- efetch: `efetch.fcgi?db=pubmed&id=PMID&rettype=xml`
- Rate limit: 3 requests/second without API key, 10 with key

### B. Zotero Connector API Reference
- saveItems: `POST /connector/saveItems`
- Payload: `{ "items": [...], "uri": "..." }`

### C. RIS Format Reference
```
TY  - JOUR          (Type)
TI  - Title         (Title)
AU  - Author        (Author, repeatable)
JO  - Journal       (Journal)
PY  - 2024          (Year)
VL  - 1             (Volume)
IS  - 2             (Issue)
SP  - 100           (Start Page)
EP  - 110           (End Page)
DO  - 10.1000/xyz   (DOI)
AN  - 12345678      (PMID in PubMed exports)
AB  - Abstract...   (Abstract)
KW  - keyword       (Keywords, repeatable)
ER  -               (End of Record)
```
